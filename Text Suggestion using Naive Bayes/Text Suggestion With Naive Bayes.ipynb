{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Libraries\n",
    "import nltk\n",
    "from nltk import bigrams,trigrams \n",
    "from nltk.corpus import reuters\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import WikiCorpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\gensim\\utils.py:1268: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected %s; aliasing chunkize to chunkize_serial\" % entity)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object WikiCorpus.get_texts at 0x0000023C0E153CF0>\n"
     ]
    }
   ],
   "source": [
    "pathForWikiDataset = datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')\n",
    "wikiSentences = WikiCorpus(pathForWikiDataset).get_texts()\n",
    "print(wikiSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     E:\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     E:\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['ASIAN', 'EXPORTERS', 'FEAR', 'DAMAGE', 'FROM', 'U', '.', 'S', '.-', 'JAPAN', 'RIFT', 'Mounting', 'trade', 'friction', 'between', 'the', 'U', '.', 'S', '.', 'And', 'Japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'Asia', \"'\", 's', 'exporting', 'nations', 'that', 'the', 'row', 'could', 'inflict', 'far', '-', 'reaching', 'economic', 'damage', ',', 'businessmen', 'and', 'officials', 'said', '.'], ['They', 'told', 'Reuter', 'correspondents', 'in', 'Asian', 'capitals', 'a', 'U', '.', 'S', '.', 'Move', 'against', 'Japan', 'might', 'boost', 'protectionist', 'sentiment', 'in', 'the', 'U', '.', 'S', '.', 'And', 'lead', 'to', 'curbs', 'on', 'American', 'imports', 'of', 'their', 'products', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "# get Reuters DataSet\n",
    "nltk.download('punkt')\n",
    "nltk.download('reuters')\n",
    "reutersSentences  = reuters.sents()\n",
    "print(reutersSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureProbability(sentenceModel):\n",
    "  for nextWord in sentenceModel:\n",
    "    nextWords = sentenceModel[nextWord]\n",
    "    total_Word_Count = float(sum(nextWords.values()))\n",
    "    for previousWord in nextWords:\n",
    "      nextWords[previousWord]/=total_Word_Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def measureSigleWordProbability(sentenceModel,wordCount):\n",
    "  for word in sentenceModel:\n",
    "    sentenceModel[word]/=wordCount\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def convertToLower(item):\n",
    "  if type(item)==str:\n",
    "    return item.lower()\n",
    "  return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceModelLambda1 = defaultdict(lambda: set())\n",
    "sentenceModelLambda2 = defaultdict(lambda: set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureWordCount(sentenceModel1,sentenceModel2,sentenceModel3,sentences):\n",
    "  wordCount = 0\n",
    "  for sentence in sentences:\n",
    "    for word in sentence:\n",
    "      wordCount+=1\n",
    "      sentenceModel1[word]+=1\n",
    "    for previousWord2,previousWord1,nextWord in trigrams(sentence,pad_right=True,pad_left=True):\n",
    "      previousWord1 = convertToLower(previousWord1)\n",
    "      previousWord2 = convertToLower(previousWord2)\n",
    "      nextWord = convertToLower(nextWord)\n",
    "      sentenceModel2[nextWord][previousWord1]+=1\n",
    "      sentenceModel3[nextWord][previousWord2]+=1\n",
    "      sentenceModelLambda1[previousWord1].add(nextWord)\n",
    "      sentenceModelLambda2[previousWord2].add(nextWord)\n",
    "\n",
    "  return wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceModel1 = defaultdict(lambda:0)\n",
    "sentenceModel2 = defaultdict(lambda: defaultdict(lambda:0))\n",
    "sentenceModel3 = defaultdict(lambda: defaultdict(lambda:0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452944\n"
     ]
    }
   ],
   "source": [
    "wikiCount = measureWordCount(sentenceModel1,sentenceModel2,sentenceModel3,wikiSentences)\n",
    "print(wikiCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1720917\n"
     ]
    }
   ],
   "source": [
    "reutersCount = measureWordCount(sentenceModel1,sentenceModel2,sentenceModel3,reutersSentences)\n",
    "print(reutersCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "measureProbability(sentenceModel2)\n",
    "measureProbability(sentenceModel3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = wikiCount + reutersCount\n",
    "measureSigleWordProbability(sentenceModel1,total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('is', 2.684929364088014e-08) ('to', 1.1753701280369164e-09) (',', 5.59438489695973e-10) ('in', 4.6278217257881707e-10) ('and', 4.5063509855288127e-10) ('for', 3.738790783749001e-10) ('would', 3.5383441884561533e-10) ('will', 2.8735045390861837e-10) ('that', 2.0690529880634479e-10) ('or', 1.711572663102755e-10)\n"
     ]
    }
   ],
   "source": [
    "maxProbabilityWords = []\n",
    "def makeWordSuggestionByTrigram(previousWord2,previousWord1):\n",
    "  for nextWord in sentenceModelLambda1[previousWord1] & sentenceModelLambda2[previousWord2]:\n",
    "    naiveBiasTrigramWeight = sentenceModel1[nextWord]*sentenceModel2[nextWord][previousWord1]*sentenceModel3[nextWord][previousWord2]\n",
    "    maxProbabilityWords.append((nextWord,naiveBiasTrigramWeight))\n",
    "makeWordSuggestionByTrigram('my','name')\n",
    "maxProbabilityWords.sort(key=lambda o:o[1],reverse=True)\n",
    "print(*maxProbabilityWords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    text = input(\"Enter your line: \")\n",
    "    if text == \"stop\":\n",
    "        print(\"Ending The Program.....\")\n",
    "        break\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            maxProbabilityWords = []\n",
    "            text = text.split(\" \")\n",
    "            makeWordSuggestionByTrigram(text[0],text[1])\n",
    "            maxProbabilityWords.sort(key=lambda o:o[1],reverse=True)\n",
    "            print(*maxProbabilityWords[:10])\n",
    "            \n",
    "        except:\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
